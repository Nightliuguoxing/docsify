# ML23 - Logistic Regression Cost Function

### 代价函数

Training set : $ \{ (x^{(1)},y^{(1)}), \ (x^{(2)},y^{(2)}), \ \cdots, \ (x^{(m)},y^{(m)}) \} $  
m examples $ \quad x \in 
\begin{bmatrix}
{x_0}\\
{x_1}\\
{\vdots}\\
{x_n}\\
\end{bmatrix} \quad
x_0 \ = \ 1, \ y \in \{0, 1\} $  
$ h_\theta (x) \ = \ \frac{1}{1+e^{-\theta^Tx}} $  
How to choose parameters $\theta$ ? 


### Cost Function
Linear regression: $$ J(\theta) = \frac{1}{m} \displaystyle\sum_{i=1}^m cost(h_{\theta}(x^{(i)}), \ y^{(i)})  $$
$ cost(h_{\theta}(x^{(i)}), \ y^{(i)}) = \frac{1}{2}( h_{\theta}(x^{(i)}) - y^{(i)})^2 $  

### Logistic Regression cost function
$ Cost(h_\theta(x), \ y) = 
\begin{cases}
\quad \ \ -log(h_\theta(x)) \quad if \ y \ = \ 1 \\
-log(1 - h_\theta(x)) \quad if \ y \ = \ 0
\end{cases}
$