# ML39 - Neural Networks: Learning - Implementation note: Unrolling parameters

### 展开参数

**Advanced optimization**  
```octave
function [jVal, gradient] = costFunction(theta)
···
optTheta = fminunc(@costFunction, initialTheta, options)
```
Neural Network (L = 4):  
$ \quad \quad  \Theta^{(1)}, \ \Theta^{(2)}, \ \Theta^{(3)} $ - matrices (Theta1, Theta2, Theta3)   
$ \quad \quad \mathtt{D}^{(1)}, \ \mathtt{D}^{(2)}, \ \mathtt{D}^{(3)} $ - matrices (D1, D2, D3)  
"Unroll" into vectors

**Example**  
$ s_1 = 10, s_2 = 10, s_3 = 1 $  
$ \Theta^{(1)} \in \mathbb{R}^{10 \times 11}, \ \Theta^{(2)} \in \mathbb{R}^{10 \times 11}, \ \Theta^{(3)} \in \mathbb{R}^{1 \times 11} $    
$ D^{(1)} \in \mathbb{R}^{10 \times 11}, \ D^{(2)} \in \mathbb{R}^{10 \times 11}, \ D^{(3)} \in \mathbb{R}^{1 \times 11} $

```octave
thetaVec = [Theta1(:); Theta2(:); Theta3(:)];
DVec = [D1(:); D2(:); D3(:)];

Theta1 = reshape(thetaVec(1 : 110), 10, 11);
Theta2 = reshape(thetaVec(111 : 220), 10, 11);
Theta3 = reshape(thetaVec(221 : 231), 1, 11);
```

**Learning Algorithm**  
Have ini5al parameters $ \Theta^{(1)}, \ \Theta^{(2)}, \ \Theta^{(3)} $  
Unroll to get `initialTheta` to pass to	 

```octave
fminunc(@costFunction, initialTheta, options)  
```

```octave
function [jval, gradientVec] = costFunction(thetaVec)  
```

From thetaVec, get $ \Theta^{(1)}, \ \Theta^{(2)}, \ \Theta^{(3)} $  
Use	forward prop/back prop to compute $ \mathtt{D}^{(1)}, \ \mathtt{D}^{(2)}, \ \mathtt{D}^{(3)} $ and $ \mathtt{J}(\Theta) $  
Unroll $ \mathtt{D}^{(1)}, \ \mathtt{D}^{(2)}, \ \mathtt{D}^{(3)} $ to get `gradientVec`.